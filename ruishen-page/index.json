[{"categories":null,"contents":"This is the current project I am working on. My ultimate task is to develop better segmentation and analysis methods for thalamic \u0026amp; sub-thalamic nuclei based on multimodal MRI such as DTI/DKI and MPnRAGE. I have been conducting some experiments including investigating several fiber tractography methods solving crossing fiber problem, visualizing multimodal data using TSNE and UMAP, investigating optimization tools for difffusion kurtosis claculation and the cause of error estimation.\n","permalink":"http://localhost:1313/projects/subtha/","tags":["Python","DTI","DKI","T1W MRI","Data Visualization","Thalamic/Subthalamic nuclei","Optimization"],"title":"Sub-thalamic nuclei Segmentation"},{"categories":null,"contents":"","permalink":"http://localhost:1313/publications/ivasismrm2018/","tags":null,"title":"Integrated vascular (iVas) MRI in brain tumor"},{"categories":null,"contents":"This project\u0026rsquo;s object was to estimate the 6 degrees-of-freedom pose of the mobile C-arm imaging device based on a single image. The motivation of this work was to determine the best device position within limited X-ray shots in order to reduce unnecessary radiation exposure administered by the system. My work involved investigating different design markers by which to encode the device pose, and I decoding the pose through segmentation and registration methods. In addition, I developed an end-to-end learning scheme to train a deep neural network based on the whole image information, using tens of thousands synthetic X-ray data I generated. Also, I applied homoscedasticity uncertainty in the neural network to estimate the error balancing ratio in order to reduce hyperparameter tuning.\n","permalink":"http://localhost:1313/projects/pose/","tags":["Python","Tensorflow","OpenCV","Registration","Mobile C-arm","X-ray","PoseNet","Homoscedasticity Uncertainty"],"title":"Mobile C-arm Pose Estimation"},{"categories":null,"contents":"Practicing handwriting using the copybook of calligraphy is suffering because we usually don\u0026rsquo;t know how good we write and how much we can improve it. So we developed Master Writing to help people conquer it. Master Writing is an IOS application that helps people improve handwriting by showing how a master is writing and let people imitate it. Users can learn how to master different fonts by practicing writing letters, words and sentences. The strokes, force and angel are recorded when users are writing. These information are compared with a master\u0026rsquo;s, and various feedbacks are provided interactively at the same time to tell people how to improve. This app was developed by me and two friends within 36 hours during Hophacks 2018 spring won Second Price Overall.\n","permalink":"http://localhost:1313/projects/write/","tags":["Swift","Apple Pencil","Apple APIs","Python","OpenCV","IOS","Segmentation","UI Design","Real-time Feedback"],"title":"Master Writing IOS App"},{"categories":null,"contents":"This is my course project for Wavelets course. The motivition of this project is to utilize wavelets characteristics to address the privacy concern in medical image database system. During the course I was thinking if we can store sensitive patient information invisibly using wavelets watermarking technique. I designed my soluttion with the following features: non-ROI segmentation, ensure watermarking will never modify ROI parta sparse matrix generated by a private-key to determine the location of non-ROI modification. enhance the security of patient datawavelets encoding, changes the least significant bits to store informationBCH coding for noise detection and correction to enhance robustnessembedded additional logol image for tamper detection\n","permalink":"http://localhost:1313/projects/watermarking/","tags":["Wavelets","Segmentation","Sparse matrix","BCH","Matlab","Tamper detection"],"title":"Wavelet Based ROI-Preserving Medical Image Watermarking Scheme"},{"categories":null,"contents":"Gas-inhalation magnetic resonance imaging (MRI) is a novel imaging technique to measure multiple brain hemodynamic parameters, such as cerebrovascular reactivity (CVR), cerebral blood volume (CBV), bolus arrival time (BAT) and functional connectivity (FC). This technique uses two physiological measures, specifically arterial CO2 and O2 time course, as input and BOLD MRI signal time course as output, and employs a linear model to determine the association between gas challenge and MRI signal, which is related to vascular properties of the brain. A prerequisite of this analysis is that the CO2 and O2 time course needs to be aligned temporally. However, in practice, the CO2 and O2 recordings are obtained from different instruments thus they are not always properly aligned. In this project, I developed a simple and fully automated method to synchronize the CO2 and O2 signals, based on time-shifted correlation of these two signals. The proposed algorithm may be a useful tool in pre-processing of gas-inhalation MRI data.\n","permalink":"http://localhost:1313/projects/ivas/","tags":["iVas MRI","Signal Synchronization","Matlab"],"title":"Integrated vascular (iVas) MRI"},{"categories":null,"contents":"","permalink":"http://localhost:1313/publications/foetalismrm2017/","tags":null,"title":"A pilot study of lateral ventricle volume from in utero foetal brain magnetic resonance imaging (MRI)"},{"categories":null,"contents":"","permalink":"http://localhost:1313/publications/gridradiology2018/","tags":null,"title":"Design and Application of fMRI Paradigm referred to Spatial navigation Based on Grid Cell Symmetry"},{"categories":null,"contents":"Overview  This is my bachelor graduation project in 2016. Inspired by Bellmund\u0026rsquo;s paper \u0026ldquo;Grid-cell representations in mental simulation\u0026rdquo; published in August 2016, I was thinking if grid-like representations can be activated given more abstract and simple cues, and can be detected using fMRI. The motivation was to simplify the original experimental paradigm from the paper, in order to make it possible to use in wider clinical trails and measurements. In my graduation project, I first implemented the navigation task in virtual-reality city using Unity3D. By analyzing fMRI signals of subjects conducting the task, we observed the sinusoidal signals as a function of moving direction successfully, which confirmed the recent published discovery of grid cell firing pattern. Then I designed a modified paradigm using PyQt based on my assumption, which only kept the location relationship in previous task and represented them in 2D plane, without other 3D visual cues. we collected fMRI data of 10 subjects and conducted the same analyzation using DPABI and SPM, among which 9 subjects had positive activation. I was awarded Outstanding Graduation Project in June 2017. Spatial navigation in virtual reality environment   This spatial navigation task was based on the experiment in Bellmund\u0026rsquo;s paper \u0026ldquo;Grid-cell representations in mental simulation\u0026rdquo;. I created a virtual reality environment using Unity3D, computer graphics engine. In this city-view virtual reality environment, we put objects (sculpture, car, phone booth, etc.) at vertices (red points) of hexagons as shown in Fig 1, and we set an another object (billboard) at the center of the city (yellow point) as the departure location. Subjects explore the virtual reality city and memorize the location of the objects in the training phase. In the testing phase, they conduct spatial memory task illustrated in Fig 2, and their brain signals are recorded using fMRI in the meantime. We repeated the results in the paper, suggesting that the activation pattern has highest similarity when imagine spatial direction at 0 degree modulo 60 degree condition, and has lowest similarity at 30 degree modulo 60 degree condition.  Fig 1. Overview of the virtual reality city   Fig 2. Spatial navigation task in virtual reality environment  Spatial memory task with 2D abstract cues  Fig 3. Overview of the 2D environment  In this spatial memory task, we kept the location relationship of the objects and illustrated then using only 2D abstract cues (basic geometric shape) as shown in Fig 3. We used yellow circle representing the refference object, red circles representing the target objects, green circles at the center of the view representing the location of subjects themselves, and the green triangular pointing their facing direction. In the training phase, subjects can move and rotate in the 2D abstract environment as shown in Fig 4. Only a limited view (area in the big sector) is available during their movement while the remaining part is shaded. In the testing phase, subjects first learn the location relationship between reference object (yellow circle), target object (red circle) and themselves (green circle). Then a reference object will appear on the screen and subject need to adjust their facing direction according to previouly learned relationship. After that, subjects need to estimate the position of the target object based on their current facing direction. In the feedback phase, subject provide their confidence level and the correct direction of objects will appear on the screen. This paradigm was implemented using PyQt.  Fig 4. Training phase of 2D abstract environment (move/rotate)   Fig 5. Testing phase of 2D spatial memory task (learn/test)  Fig 6. Spatial memory task with 2D abstract cues  fMRI recording  We collected fMRI data of 10 subjects and conducted analyzation using DPABI and SPM, among which 9 subjects had significat activation (P=0.01) at entorhinal cortex (EC) during the spatial memory task in 2D abstract environment. Fig 7 shows an example EC activation of a subject. Fig 7. fMRI recordings of entorhinal cortex (P=0.01)  Fig 8. Angle modulo 60 degree activation pattern   We compare the correlation coefficients of EC activations of trial pairs respect to their angular difference (in modulo 60 degree condition) of sampled testing directions. The results in Fig 8 show that angular difference at 0 degree has highest similarity, while angular difference at 30 degree has lowest similarity. The firing rate of the hypothetical response of the grid cell as a function of direction, showing a 60 degree modulation. According to this grid cell model, we can expect 60 degree modulation of fMRI pattern similarity values when comparing trial pairs based on the angular difference of their sampled testing directions. Our results satisfied the expectation. ","permalink":"http://localhost:1313/projects/grid/","tags":["Grid Cell","fMRI","Paradigm Design","Unity3D","Python","PyQt","Matlab","SPM","DPABI"],"title":"Paradigm Design for Grid Cell Study"},{"categories":null,"contents":"This project was to investigate super resolution reconstruction of lateral ventricle volume from fetal brain MRI data. The most challenging aspect of the project was to deal with the inter-slice noise caused by fetal head motion. We implemented a reconstruction method in my co-authored paper published in ISMRM, where we first modeled degradation and realigned low-resolution images via convex optimization in order to reduce motion artifacts. This result along with additional data from the same gestation week was used in a sparse reconstruction algorithm to achieve the desired super-resolution.\n","permalink":"http://localhost:1313/projects/fetal/","tags":["Fetal Brain MRI","Sparse Reconstruction","Super Resolution","Optimization"],"title":"Fetal Brain Reconstruction from MRI"},{"categories":null,"contents":"This is a small prject I have been working on when I first joined Medical Electronics Laboratory in Southeast University. My task was to extract and analyze the real-time heart rate from PPG signals. I investigated Hilbert-Huang transform (HHT), short-time Fourier transform (STFT) and continuous wavelets transform (CWT) in this project.\n","permalink":"http://localhost:1313/projects/hht/","tags":["PPG","Heart Rate","HHT","STFT","CWT","Matlab"],"title":"Heart Rate Monitoring from PPG"},{"categories":null,"contents":"This student project was conducted on 2016 at my junior year. It stemmed from one of my thoughts \u0026mdash; can we detect lip movements with micro-camera, transfer lip language to synthetic voice, thus enabling the mute to communicate just like us? we took 10000 photos of Chinese speakers speaking basic vowels, conducted automatic detection of faces and lips with OpenCV, and trained a neural network to recognize basic Chinese vowels. We built a lip language reader using Raspberry Pi and a camera with 92.03 recognition accuracy. This project was also funded by National Undergraduate Innovation \u0026amp; Entrepreneurship program.\n","permalink":"http://localhost:1313/projects/lip/","tags":["Lip reading","Segmentation","Neural Networks","OpenCV","Python","Matlab","Raspberry Pi"],"title":"Lip Language Recognition"},{"categories":null,"contents":"ADS-B (Automatic dependent surveillance—broadcast) is \u0026ldquo;a surveillance technology in which an aircraft determines its position via satellite navigation and periodically broadcasts it, enabling it to be tracked.\u0026rdquo; I worked on this student project with two friends when we were sophomores. We built an reliable aircraft monitoring system with 200km detection zone, based on ADS-B technology. We improved the performance of the receiver at 1090MHz by making an extensional coaxial collinear antenna ourself. We obtained real-time aircraft data using rtl-sdr and provided the website service for two years to visualize the aircraft information. We also conducted some blind sourse seperation experiments on aliased 1090ES signals. We won about $3000 fund from National Undergraduate Innovation \u0026amp; Entrepreneurship program, and was awarded Outstanding Project.\n","permalink":"http://localhost:1313/projects/adsb/","tags":["ADS-B","rtl-sdr","Coaxial Antenna","Python","Matlab","Raspberry Pi","Arduino","XML/HTML","Baidu Map APIs","Blind Source Separation"],"title":"Aircraft Monitoring based on ADS-B"},{"categories":null,"contents":" This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;]  Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ...  Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ]  ","permalink":"http://localhost:1313/search/","tags":null,"title":"Search Results"}]